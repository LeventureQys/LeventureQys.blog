# 机器学习，从零开始

本博客页面将记录我从零开始机器学习的一些笔记和启发

## part1 绪论

1.1 浅谈一些基础概念

首先我们学习的时候要知道一些基础概念：

  1.数据集：记录的集合
  
  2.实例、样本：就是关于一个时间或对象的描述
  
  3.属性、特征：反应时间或对象在某方面的表现或者性质的事项，例如：“色泽”
  
  4.属性值： 某个事物或对象在属性上的取值，比如“乌黑”
  
  5.样本空间、属性空间、输入控件：属性张成的空间。
  
以上几个是基本概念，后续应该就不会再介绍了。

![image](https://user-images.githubusercontent.com/102945300/173177667-6975382a-6e5c-46d6-8557-f8092dc51aaf.png)

我们让机器从数据中学得模型的过程成为 学习 或者 训练 ，这个过程通过执行某个学习算法来完成。

训练用的数据成为训练数据，其中的每个样本成为训练样本。

由训练样本组成的集合成为 训练集

学的模型对应了关于数据的魔偶中潜在规律 称为  假设

而这种规律本身我们称之为 真相 或者 真实，其中整个学习过程就是为了找到或者说逼近真相。 

模型又称作学习器 learner，可看作学习算法在给定数据和参数空间上的实例化。

我们一般用![image](https://user-images.githubusercontent.com/102945300/173177808-9e86a53d-1c1c-4230-b4d4-151a95458c3e.png)表示第i个样例![image](https://user-images.githubusercontent.com/102945300/173177816-a81404c7-126f-41e7-9ea7-823322a2359a.png)

这个标记其实就是我们给定的 结果 ，比如好瓜 坏瓜，或者成熟度0.9，成熟度0.8这类的结果

如果预测离散值，我们称这种任务叫分类，如果是连续的，则称其为回归

书中提到结论：总误差和算法无关，但是不是绝对的，就比如我们可以从A地到B地，我们可以骑单车 或者打的去，但是如果从A省到B省......我们当然还是可以打的去，或者骑单车，但是这都不可能是我们想要的答案。所以要根据不同的情境来决定不同的学习偏好，这样才能让我们得到一个更好的结果，这也是机器学习的研究方向之一。

这里是第一张绪论的习题与答案：[](https://zhuanlan.zhihu.com/p/355235881?ivk_sa=1024320u)


## part2 模型评估与选择

1.精度

首先书上给出精度的概念

![image](https://user-images.githubusercontent.com/102945300/173178860-bf0d5061-cb66-47ec-b8e5-59343546ca8e.png)

我们说训练误差有两种可能，一种是学习器能力低下，丢失了很多实例的细节导致的 欠拟合 ，但是欠拟合很好解决，真正的关键障碍是学习机的学习能力过于强大导致的欠拟合。以至于把训练样本所包含的不太一般的特性都学到了，也可能导致一些舍本逐末的误差。

![image](https://user-images.githubusercontent.com/102945300/173178935-836bc42b-f8ec-4064-9139-253b3c4521d4.png)

过拟合是不可避免的，其实机器学习很多问题都是NP-Hard问题，关于什么是NP问题请参考[NP问题总结（概念+例子+证明）](https://blog.csdn.net/a12638915/article/details/105180347)

也就是说机器学习中关于模型的选择和筛选其实本质上是NP问题复杂度更高的问题，这也是不可避免的。

2.评估

我们评估的时候，会有两个已知结果的集，一个是训练集，用来训练我们的学习器，另一个是测试集，用来测试我们学习器的学习成果的，二者最好能做到尽可能互斥。我们当然是希望得到一个泛化性更强的模型，这样可以更加的反应我们学习器的学习成果，避免一些重复的经验影响到判断的结果。

当然，我们一般情况下都只会拿到一个数据集来进行训练，划分测试集和训练集一般有几种常见的做法，这里截图一下书上怎么说的

2.1留出法 

![image](https://user-images.githubusercontent.com/102945300/173179289-c7de8f87-1c8c-443d-a32b-790301eb19e3.png)

当然这样有可能导致一些问题：两个集数量严重不一致，可能S占了绝大多数，T占了绝小部分，这样就会对我们的实际测试造成很大的影响。

![image](https://user-images.githubusercontent.com/102945300/173179366-5013eada-e959-43c2-afd9-b9400a1b4623.png)

2.2交叉验证法：

就是把数据集D划分为k个大小差不多的互斥子集，然后选则其中k-1个为训练集，剩下的哪个做测试机，从而可以进行k次训练和测试

![image](https://user-images.githubusercontent.com/102945300/173179765-ba428eb3-afb3-4d50-8ced-b4ac4d49e1e6.png)

![image](https://user-images.githubusercontent.com/102945300/173179958-53ccd568-4ad5-4d3f-a4bb-4fc98b95effc.png)

![image](https://user-images.githubusercontent.com/102945300/173179963-3bffac2a-811b-48e4-8436-f6c555ac0a44.png)

2.3自助法：

我感觉它书上讲的好复杂，就是我们现在视一个总的数据集D，一个训练集集为D‘,测试集为D/D’。

我们将总的数据集D划分为m的个小的集合，然后每次我们从中取一个集合拷贝进入D'，然后我们将这个集合放回，这样我们下次采样的时候还是有可能采样到m对吧。执行m次后，我们就得到了包含m个样本的数据集D'。显然D中的样本只会有一部分出现在D'中，而另一部分不出现，计算公式如下：

![image](https://user-images.githubusercontent.com/102945300/173180387-1db32385-206d-45f8-8426-158336121c44.png)

也就是说D中有大约0.368的样本没有出现在D'中，而这部分也就是D/D'，所以我们将大的部分也就是D'占D的1-0.368作为训练集，小的部分也就是D/D'占0.368做测试集

这个方法其实有点傻逼，而且能效比说实在的比较低。用在数据集较小，难以有效划分训练集测试集的时候有用，但是量大了就是真的抽象。除此之外，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。

2.4宇宙的终极尽头：调参

![image](https://user-images.githubusercontent.com/102945300/173180657-9aff43af-bf8b-4b24-b231-d3a5754545e1.png)


3.性能度量：

最常用的性能度量就是均方误差，当然不是把每个实例的误差相加求平均就行了，要求各均方误差

![image](https://user-images.githubusercontent.com/102945300/173180755-51aa70d9-3a9a-4783-ae9a-2ae1338977bf.png)

就是学习出来的结果和实际结果之间的差求平方，再求个平均数，这个就是我们学习效果的均方误差

当然了如果是数据分布和概率密度函数的，那么我们的均方误差可以描述为上述

下面介绍一些常用的性能度量

3.1错误率和精度

以下定义一个错误率和精度

![image](https://user-images.githubusercontent.com/102945300/173180820-08f73c65-ef79-46fc-a7ed-42ea377ff202.png)

一个更一般的数据分布和概率精度函数：

![image](https://user-images.githubusercontent.com/102945300/173180963-12b7442d-586b-4bc3-b25c-c36f83fe3657.png)

3.2查准率、查全率和F1

![image](https://user-images.githubusercontent.com/102945300/173181217-2bcf1c3d-1470-40fc-92d9-8bce474b0e65.png)

我们在实际的学习中，预测的结果应该是有四类

![image](https://user-images.githubusercontent.com/102945300/173181231-acc6495c-4732-47ef-90a8-873fbd0c7a81.png)

夏然TP+FP+TN+FN=样例总数

![image](https://user-images.githubusercontent.com/102945300/173181248-e2c158c5-9c9b-4eab-a523-333388c70530.png)

二者都是只需要看真正例做分母，区别在于查准是以真正例和假正例做分母，而查全则是真正例和假反例做分母。一般来说查准率高那么查全率往往就偏低，而查全率高的时候，查准率往往就低。

也就是说，我们希望查询的对象尽可能多，那么查到我们需要的对象的几率自然就低了；如果我们希望查询的对象尽可能是我们需要的对象，那么南美就会漏掉不少的查询对象，这两种度量指标都要依靠我们的需要来选取，并不是说高了就一定好。

比如我们在瓜堆里找西瓜，有两种理想状态：1.希望尽可能地把好西瓜尽可能多地选出来，我们就会增加选瓜的数量2.如果我们希望尽可能地在有限的次数中选中好瓜的几率尽可能高，那么我们就会偏向挑选更有把我的瓜，但这样难免会漏掉不少的好瓜，使得查全率较低。通常只有在一些简单的任务，或者好瓜数量较多的任务里，查全率和查准率才有可能都会高。

注：正 反 是一个相对的概念，而真 假是一个绝对的概念，这里描述一下什么是真正例，什么是假反例

正、反指的是与我们预测的方向是否相同，而真假指的是预测结果是否与真是情况相同。

![image](https://user-images.githubusercontent.com/102945300/173181574-095968a3-1e24-40fc-9106-812be89f4bc2.png)

查准率P，查全率R

![image](https://user-images.githubusercontent.com/102945300/173181734-e7162cff-6ebb-4373-94d6-856abaa13fc8.png)
